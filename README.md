# ğŸ§  Multimodal AI Video Assistant

**Tech Stack:**  Streamlit Â· OpenAI GPT-4o Â· Whisper Â· TTS Â· OpenCV Â· FFmpeg Â· Python

## ğŸ“˜ Overview

The **Multimodal AI Video Assistant** is an AI system that performs **image and audio processing** on video files to generate structured, human-readable insights. It combines **computer vision, speech recognition, and language modeling** to deliver text-based and spoken summaries through a simple Streamlit interface.

## âš™ï¸ Features

ğŸï¸ **Frame Extraction & Sampling:** Extracts frames efficiently from videos using OpenCV and FFmpeg.

ğŸ”Š **Audio Transcription:** Converts speech to text using OpenAIâ€™s Whisper model for accurate transcription.

ğŸ§  **Multimodal Fusion:** Integrates frame and transcript data for context-aware summarization using GPT-4o.

ğŸ—£ï¸ **Text-to-Speech:** Generates a playable, downloadable audio summary through OpenAI TTS.

ğŸŒ **Interactive UI:** Streamlit-based interface for uploading videos, running the analysis, and viewing/download results.

## ğŸ§© System Architecture

 Video Input  
      â†“  
 Audio Extraction (FFmpeg)  
      â†“  
 Frame Sampling (OpenCV)  
      â†“  
 Speech-to-Text (Whisper)  
      â†“  
 GPT-4o Summarization  
      â†“  
 Output: Text Summary + TTS Audio File

## ğŸ§ª Results

- Reduced computational overhead with **frame sampling (1 frame per 5 seconds).**
- Enhanced reliability through optimized **session state management.**
- Produced concise and synchronized **text + audio summaries** from raw video content.

## ğŸ“ Process

- User uploads a video file through the Streamlit interface.
- The system extracts audio and visual frames â†’ performs transcription â†’ generates multimodal summaries.
- Combines results from both modalities to produce reliable and clean insights.
- The final text summary and TTS audio file are provided for download.

## âš¡ Challenges & Fixes

- Blank audio output: Identified root cause as incorrect TTS node mapping â†’ fixed mappings, added blank-summary checks, text chunking, and improved file handling.
- Length constraints: TTS node limited to ~4,096 characters â†’ optimized summarization prompts to fit limits while maintaining content fidelity.

## ğŸ” Use Cases

- Automated generation of daily or weekly research summaries.

Converting long-form videos, lectures, or reports into short, digestible audio briefs.

Assisting creators, journalists, and analysts with multimodal content analysis.

## â–¶ï¸ Next Steps

Extend to mini-podcast generation with â‰¤60-second summaries.

Support multi-topic batching and scheduled digest creation.

Add transcript export alongside audio output for accessibility.

Riya Kalyan Kerur
Masterâ€™s Student, Computer Engineering â€” California State University, Sacramento
ğŸŒ LinkedIn
